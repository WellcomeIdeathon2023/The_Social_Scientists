most_common_hashtags <- names(top_hashtags)
# Create new variables for the most common hashtags
for (hashtag in most_common_hashtags) {
hashtag_column <- paste0("hashtag_", hashtag)  # Add prefix "hashtag_" to the column name
data[[hashtag_column]] <- ifelse(grepl(hashtag, data$hashtags), 1, 0)
}
write.csv(data, "vax_tweets_5.csv", row.names = FALSE)
View(data)
# Get the directory of the R script
script_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
# Set the working directory
setwd(file.path(script_dir, "../data"))
data = read.csv("classified.csv")
tweets = read.csv("vax_tweets_5.csv")
summary(tweets$X)
# Check for missing numbers in the "X" column
missing_numbers <- setdiff(1:100000, unique(tweets$X))
merged_data <- merge(data, tweets, by = "X")
merged_data$misinformation = as.factor(merged_data$misinformation)
# Assuming you have a merged dataset called merged_data with columns "misinformation" and other variables
# Set a random seed for reproducibility
set.seed(42)
# Split the data into training and testing sets using an 80:20 ratio
train_indices <- sample(nrow(merged_data), 0.8 * nrow(merged_data))
train_data <- merged_data[train_indices, ]
test_data <- merged_data[-train_indices, ]
# Load the randomForest package
library(randomForest)
# Get the column names that start with "hashtag_"
hashtag_columns <- grep("^hashtag_", colnames(data), value = TRUE)
# Create the formula for random forest, including the hashtag columns
formula <- as.formula(paste("misinformation ~ polarity_text + polarity_description + Organizations + Locations + Symptoms + COVID + Vaccination + Politics +
Conspiracy + Slurs + Masks + Miscellaneous + origin + vaccine_conspiracy + government + pharma + Five_G + gates + nwo + media", paste(hashtag_columns, collapse = "+")))
# Fit a random forest model
model <- randomForest(formula, data = train_data)
# Make predictions on the test data
predictions <- predict(model, newdata = test_data, type = "prob")
library(pROC)
# Compute the ROC curve
roc_obj <- roc(test_data$misinformation, predictions[,2])
# Plot the ROC curve
plot(roc_obj, main = "ROC Curve", print.auc = TRUE)
# Add labels and legend
legend("bottomright", legend = paste("AUC =", round(auc(roc_obj), 2)), cex = 0.8)
# Get the directory of the R script
script_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
# Set the working directory
setwd(file.path(script_dir, "../data"))
data = read.csv("classified.csv")
tweets = read.csv("vax_tweets_5.csv")
summary(tweets$X)
# Check for missing numbers in the "X" column
missing_numbers <- setdiff(1:100000, unique(tweets$X))
merged_data <- merge(data, tweets, by = "X")
merged_data$misinformation = as.factor(merged_data$misinformation)
# Assuming you have a merged dataset called merged_data with columns "misinformation" and other variables
# Set a random seed for reproducibility
set.seed(42)
# Split the data into training and testing sets using an 80:20 ratio
train_indices <- sample(nrow(merged_data), 0.8 * nrow(merged_data))
train_data <- merged_data[train_indices, ]
test_data <- merged_data[-train_indices, ]
# Load the randomForest package
library(randomForest)
# Get the column names that start with "hashtag_"
hashtag_columns <- grep("^hashtag_", colnames(data), value = TRUE)
# Create the formula for random forest, including the hashtag columns
formula <- as.formula(paste("misinformation ~ polarity_text + polarity_description + Organizations + Locations + Symptoms + COVID + Vaccination + Politics +
Conspiracy + Slurs + Masks + Miscellaneous + origin +
vaccine_conspiracy + government + pharma + Five_G +
gates + nwo + media", paste("as.factor(", hashtag_columns, ")", collapse = "+")))
# Fit a random forest model
model <- randomForest(formula, data = train_data)
# Make predictions on the test data
predictions <- predict(model, newdata = test_data, type = "prob")
library(pROC)
# Compute the ROC curve
roc_obj <- roc(test_data$misinformation, predictions[,2])
# Plot the ROC curve
plot(roc_obj, main = "ROC Curve", print.auc = TRUE)
# Add labels and legend
legend("bottomright", legend = paste("AUC =", round(auc(roc_obj), 2)), cex = 0.8)
# Load the pROC package
library(pROC)
# Compute the ROC curve
roc_obj <- roc(test_data$misinformation, prob_predictions)
# Find the threshold that maximizes Youden's Index
max_index <- which.max(roc_obj$sensitivities + roc_obj$specificities - 1)
threshold <- roc_obj$thresholds[max_index]
# Print the threshold that maximizes Youden's Index
print(paste("Threshold maximizing Youden's Index:", threshold))
# Find the observations in 'tweets' that do not have matching values in 'data$X'
validation <- anti_join(tweets, data, by = "X")
pred = predict(model, validation, type = "prob")
validation$misinformation = pred[,2]
# Apply thresholding to convert probabilities to binary predictions
validation$misinformation <- ifelse(validation$misinformation >= threshold, 1, 0)
# Print the updated 'data' dataframe with the binary predictions
summary(as.factor(validation$misinformation))
summary(as.factor(data$misinformation))
View(model)
formula
# Get the directory of the R script
script_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
# Set the working directory
setwd(file.path(script_dir, "../data"))
data = read.csv("classified.csv")
tweets = read.csv("vax_tweets_5.csv")
summary(tweets$X)
# Check for missing numbers in the "X" column
missing_numbers <- setdiff(1:100000, unique(tweets$X))
merged_data <- merge(data, tweets, by = "X")
merged_data$misinformation = as.factor(merged_data$misinformation)
# Assuming you have a merged dataset called merged_data with columns "misinformation" and other variables
# Set a random seed for reproducibility
set.seed(42)
# Split the data into training and testing sets using an 80:20 ratio
train_indices <- sample(nrow(merged_data), 0.8 * nrow(merged_data))
train_data <- merged_data[train_indices, ]
test_data <- merged_data[-train_indices, ]
# Load the randomForest package
library(randomForest)
# Get the column names that start with "hashtag_"
hashtag_columns <- grep("^hashtag_", colnames(tweets), value = TRUE)
# Create the formula for random forest, including the hashtag columns
formula <- as.formula(paste("misinformation ~ polarity_text + polarity_description + Organizations + Locations + Symptoms + COVID + Vaccination + Politics +
Conspiracy + Slurs + Masks + Miscellaneous + origin +
vaccine_conspiracy + government + pharma + Five_G +
gates + nwo + media", paste("as.factor(", hashtag_columns, ")", collapse = "+")))
# Fit a random forest model
model <- randomForest(formula, data = train_data)
# Make predictions on the test data
predictions <- predict(model, newdata = test_data, type = "prob")
library(pROC)
# Compute the ROC curve
roc_obj <- roc(test_data$misinformation, predictions[,2])
# Plot the ROC curve
plot(roc_obj, main = "ROC Curve", print.auc = TRUE)
# Add labels and legend
legend("bottomright", legend = paste("AUC =", round(auc(roc_obj), 2)), cex = 0.8)
# Load the pROC package
library(pROC)
# Compute the ROC curve
roc_obj <- roc(test_data$misinformation, prob_predictions)
# Find the threshold that maximizes Youden's Index
max_index <- which.max(roc_obj$sensitivities + roc_obj$specificities - 1)
threshold <- roc_obj$thresholds[max_index]
# Print the threshold that maximizes Youden's Index
print(paste("Threshold maximizing Youden's Index:", threshold))
# Find the observations in 'tweets' that do not have matching values in 'data$X'
validation <- anti_join(tweets, data, by = "X")
pred = predict(model, validation, type = "prob")
validation$misinformation = pred[,2]
# Apply thresholding to convert probabilities to binary predictions
validation$misinformation <- ifelse(validation$misinformation >= threshold, 1, 0)
# Print the updated 'data' dataframe with the binary predictions
summary(as.factor(validation$misinformation))
summary(as.factor(data$misinformation))
# Create the formula for random forest, including the hashtag columns
formula <- as.formula(paste("misinformation ~ polarity_text + polarity_description + Organizations + Locations + Symptoms + COVID + Vaccination + Politics +
Conspiracy + Slurs + Masks + Miscellaneous + origin +
vaccine_conspiracy + government + pharma + Five_G +
gates + nwo + media", paste("as.factor(", hashtag_columns, ")", collapse = "+")))
# Get the directory of the R script
script_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
# Set the working directory
setwd(file.path(script_dir, "../data"))
data = read.csv("classified.csv")
tweets = read.csv("vax_tweets_5.csv")
summary(tweets$X)
# Check for missing numbers in the "X" column
missing_numbers <- setdiff(1:100000, unique(tweets$X))
merged_data <- merge(data, tweets, by = "X")
merged_data$misinformation = as.factor(merged_data$misinformation)
# Assuming you have a merged dataset called merged_data with columns "misinformation" and other variables
# Set a random seed for reproducibility
set.seed(42)
# Split the data into training and testing sets using an 80:20 ratio
train_indices <- sample(nrow(merged_data), 0.8 * nrow(merged_data))
train_data <- merged_data[train_indices, ]
test_data <- merged_data[-train_indices, ]
# Load the randomForest package
library(randomForest)
# Get the column names that start with "hashtag_"
hashtag_columns <- grep("^hashtag_", colnames(tweets), value = TRUE)
# Create the formula for random forest, including the hashtag columns
formula <- as.formula(paste("misinformation ~ polarity_text + polarity_description + Organizations + Locations + Symptoms + COVID + Vaccination + Politics +
Conspiracy + Slurs + Masks + Miscellaneous + origin +
vaccine_conspiracy + government + pharma + Five_G +
gates + nwo + media +", paste("as.factor(", hashtag_columns, ")", collapse = "+")))
# Fit a random forest model
model <- randomForest(formula, data = train_data)
# Make predictions on the test data
predictions <- predict(model, newdata = test_data, type = "prob")
library(pROC)
# Compute the ROC curve
roc_obj <- roc(test_data$misinformation, predictions[,2])
# Plot the ROC curve
plot(roc_obj, main = "ROC Curve", print.auc = TRUE)
# Add labels and legend
legend("bottomright", legend = paste("AUC =", round(auc(roc_obj), 2)), cex = 0.8)
# Load the pROC package
library(pROC)
# Compute the ROC curve
roc_obj <- roc(test_data$misinformation, prob_predictions)
# Find the threshold that maximizes Youden's Index
max_index <- which.max(roc_obj$sensitivities + roc_obj$specificities - 1)
threshold <- roc_obj$thresholds[max_index]
# Print the threshold that maximizes Youden's Index
print(paste("Threshold maximizing Youden's Index:", threshold))
# Find the observations in 'tweets' that do not have matching values in 'data$X'
validation <- anti_join(tweets, data, by = "X")
pred = predict(model, validation, type = "prob")
validation$misinformation = pred[,2]
# Apply thresholding to convert probabilities to binary predictions
validation$misinformation <- ifelse(validation$misinformation >= threshold, 1, 0)
# Print the updated 'data' dataframe with the binary predictions
summary(as.factor(validation$misinformation))
summary(as.factor(data$misinformation))
# Get the directory of the R script
script_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
# Set the working directory
setwd(file.path(script_dir, "../data"))
data = read.csv("classified.csv")
tweets = read.csv("vax_tweets_5.csv")
summary(tweets$X)
# Check for missing numbers in the "X" column
missing_numbers <- setdiff(1:100000, unique(tweets$X))
merged_data <- merge(data, tweets, by = "X")
merged_data$misinformation = as.factor(merged_data$misinformation)
# Assuming you have a merged dataset called merged_data with columns "misinformation" and other variables
# Set a random seed for reproducibility
set.seed(42)
# Split the data into training and testing sets using an 80:20 ratio
train_indices <- sample(nrow(merged_data), 0.8 * nrow(merged_data))
train_data <- merged_data[train_indices, ]
test_data <- merged_data[-train_indices, ]
# Load the randomForest package
library(randomForest)
# Get the column names that start with "hashtag_"
hashtag_columns <- grep("^hashtag_", colnames(tweets), value = TRUE)
# Create the formula for random forest, including the hashtag columns
formula <- as.formula(paste("misinformation ~ polarity_text + polarity_description + Organizations + Locations + Symptoms + COVID + Vaccination + Politics +
Conspiracy + Slurs + Masks + Miscellaneous + origin +
vaccine_conspiracy + government + pharma + Five_G +
gates + nwo + media +", paste("as.factor(", hashtag_columns, ")", collapse = "+")))
# Fit a random forest model
model <- randomForest(formula, data = train_data)
# Make predictions on the test data
predictions <- predict(model, newdata = test_data, type = "prob")
library(pROC)
# Compute the ROC curve
roc_obj <- roc(test_data$misinformation, predictions[,2])
# Plot the ROC curve
plot(roc_obj, main = "ROC Curve", print.auc = TRUE)
# Add labels and legend
legend("bottomright", legend = paste("AUC =", round(auc(roc_obj), 2)), cex = 0.8)
# Load the pROC package
library(pROC)
# Compute the ROC curve
roc_obj <- roc(test_data$misinformation, prob_predictions)
# Find the threshold that maximizes Youden's Index
max_index <- which.max(roc_obj$sensitivities + roc_obj$specificities - 1)
threshold <- roc_obj$thresholds[max_index]
# Print the threshold that maximizes Youden's Index
print(paste("Threshold maximizing Youden's Index:", threshold))
# Find the observations in 'tweets' that do not have matching values in 'data$X'
validation <- anti_join(tweets, data, by = "X")
pred = predict(model, validation, type = "prob")
validation$misinformation = pred[,2]
# Apply thresholding to convert probabilities to binary predictions
validation$misinformation <- ifelse(validation$misinformation >= threshold, 1, 0)
# Print the updated 'data' dataframe with the binary predictions
summary(as.factor(validation$misinformation))
summary(as.factor(data$misinformation))
# Create the formula for random forest, including the hashtag columns
formula <- as.formula(paste("misinformation ~ polarity_text + polarity_description + Organizations + Locations + Symptoms + COVID + Vaccination + Politics +
Conspiracy + Slurs + Masks + Miscellaneous + origin +
vaccine_conspiracy + government + pharma + Five_G +
gates + nwo + media +", paste("as.factor(", hashtag_columns, ")", collapse = "+")))
formuka
formula
# Create the formula for random forest, including the hashtag columns
formula <- as.formula(paste("misinformation ~ polarity_text + polarity_description + Organizations + Locations + Symptoms + COVID + Vaccination + Politics +
Conspiracy + Slurs + Masks + Miscellaneous + origin +
vaccine_conspiracy + government + pharma + Five_G +
gates + nwo + media +", paste("as.factor(", paste(hashtag_columns, collapse = "+"), ")", sep = ""), collapse = " "))
formula
# Fit a random forest model
model <- randomForest(formula, data = train_data)
View(train_data)
# Get the directory of the R script
script_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
# Set the working directory
setwd(file.path(script_dir, "../data"))
data = read.csv("classified.csv")
tweets = read.csv("vax_tweets_5.csv")
summary(tweets$X)
# Check for missing numbers in the "X" column
missing_numbers <- setdiff(1:100000, unique(tweets$X))
merged_data <- merge(data, tweets, by = "X")
merged_data$misinformation = as.factor(merged_data$misinformation)
# Assuming you have a merged dataset called merged_data with columns "misinformation" and other variables
# Set a random seed for reproducibility
set.seed(42)
# Split the data into training and testing sets using an 80:20 ratio
train_indices <- sample(nrow(merged_data), 0.8 * nrow(merged_data))
train_data <- merged_data[train_indices, ]
test_data <- merged_data[-train_indices, ]
# Load the randomForest package
library(randomForest)
# Get the column names that start with "hashtag_"
hashtag_columns <- grep("^hashtag_", colnames(tweets), value = TRUE)
# Create the formula for random forest, including the hashtag columns
formula <- as.formula(paste("misinformation ~ polarity_text + polarity_description + Organizations + Locations + Symptoms + COVID + Vaccination + Politics +
Conspiracy + Slurs + Masks + Miscellaneous + origin +
vaccine_conspiracy + government + pharma + Five_G +
gates + nwo + media +", paste("as.factor(", paste(hashtag_columns, collapse = "+"), ")", sep = ""), collapse = " "))
formula
# Fit a random forest model
model <- randomForest(formula, data = train_data)
# Create the formula for random forest, including the hashtag columns
formula <- as.formula(paste("misinformation ~ polarity_text + polarity_description + Organizations + Locations + Symptoms + COVID + Vaccination + Politics +
Conspiracy + Slurs + Masks + Miscellaneous + origin +
vaccine_conspiracy + government + pharma + Five_G +
gates + nwo + media +", paste("as.factor(", paste(hashtag_columns, collapse = " + "), ")", sep = ""), collapse = " + "))
formula
# Create the formula for random forest, including the hashtag columns
formula <- as.formula(paste("misinformation ~ polarity_text + polarity_description + Organizations + Locations + Symptoms + COVID + Vaccination + Politics +
Conspiracy + Slurs + Masks + Miscellaneous + origin +
vaccine_conspiracy + government + pharma + Five_G +
gates + nwo + media +", paste(hashtag_columns, collapse = " + "), collapse = " + "))
formula
# Get the directory of the R script
script_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
# Set the working directory
setwd(file.path(script_dir, "../data"))
data = read.csv("classified.csv")
tweets = read.csv("vax_tweets_5.csv")
summary(tweets$X)
# Check for missing numbers in the "X" column
missing_numbers <- setdiff(1:100000, unique(tweets$X))
merged_data <- merge(data, tweets, by = "X")
merged_data$misinformation = as.factor(merged_data$misinformation)
# Assuming you have a merged dataset called merged_data with columns "misinformation" and other variables
# Set a random seed for reproducibility
set.seed(42)
# Split the data into training and testing sets using an 80:20 ratio
train_indices <- sample(nrow(merged_data), 0.8 * nrow(merged_data))
train_data <- merged_data[train_indices, ]
test_data <- merged_data[-train_indices, ]
# Load the randomForest package
library(randomForest)
# Get the column names that start with "hashtag_"
hashtag_columns <- grep("^hashtag_", colnames(tweets), value = TRUE)
# Create the formula for random forest, including the hashtag columns
formula <- as.formula(paste("misinformation ~ polarity_text + polarity_description + Organizations + Locations + Symptoms + COVID + Vaccination + Politics +
Conspiracy + Slurs + Masks + Miscellaneous + origin +
vaccine_conspiracy + government + pharma + Five_G +
gates + nwo + media +", paste(hashtag_columns, collapse = " + "), collapse = " + "))
formula
# Fit a random forest model
model <- randomForest(formula, data = train_data)
# Make predictions on the test data
predictions <- predict(model, newdata = test_data, type = "prob")
library(pROC)
# Compute the ROC curve
roc_obj <- roc(test_data$misinformation, predictions[,2])
# Plot the ROC curve
plot(roc_obj, main = "ROC Curve", print.auc = TRUE)
# Add labels and legend
legend("bottomright", legend = paste("AUC =", round(auc(roc_obj), 2)), cex = 0.8)
# Load the pROC package
library(pROC)
# Compute the ROC curve
roc_obj <- roc(test_data$misinformation, prob_predictions)
# Find the threshold that maximizes Youden's Index
max_index <- which.max(roc_obj$sensitivities + roc_obj$specificities - 1)
threshold <- roc_obj$thresholds[max_index]
# Print the threshold that maximizes Youden's Index
print(paste("Threshold maximizing Youden's Index:", threshold))
# Find the observations in 'tweets' that do not have matching values in 'data$X'
validation <- anti_join(tweets, data, by = "X")
pred = predict(model, validation, type = "prob")
validation$misinformation = pred[,2]
# Apply thresholding to convert probabilities to binary predictions
validation$misinformation <- ifelse(validation$misinformation >= threshold, 1, 0)
# Print the updated 'data' dataframe with the binary predictions
summary(as.factor(validation$misinformation))
summary(as.factor(data$misinformation))
View(tweets)
# Get the directory of the R script
script_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
# Set the working directory
setwd(file.path(script_dir, "../data"))
data = read.csv("classified.csv")
tweets = read.csv("vax_tweets_5.csv")
summary(tweets$X)
# Check for missing numbers in the "X" column
missing_numbers <- setdiff(1:100000, unique(tweets$X))
merged_data <- merge(data, tweets, by = "X")
merged_data$misinformation = as.factor(merged_data$misinformation)
# Assuming you have a merged dataset called merged_data with columns "misinformation" and other variables
# Set a random seed for reproducibility
set.seed(42)
# Split the data into training and testing sets using an 80:20 ratio
train_indices <- sample(nrow(merged_data), 0.8 * nrow(merged_data))
train_data <- merged_data[train_indices, ]
test_data <- merged_data[-train_indices, ]
# Load the randomForest package
library(randomForest)
# Get the column names that start with "hashtag_"
hashtag_columns <- grep("^hashtag_", colnames(tweets), value = TRUE)
# Create the formula for random forest, including the hashtag columns
formula <- as.formula(paste("misinformation ~ polarity_text + subjectivity_text + subjectivity_description + polarity_description + Organizations + Locations + Symptoms + COVID + Vaccination + Politics +
Conspiracy + Slurs + Masks + Miscellaneous + origin +
vaccine_conspiracy + government + pharma + Five_G +
gates + nwo + media +", paste(hashtag_columns, collapse = " + "), collapse = " + "))
formula
# Fit a random forest model
model <- randomForest(formula, data = train_data)
# Make predictions on the test data
predictions <- predict(model, newdata = test_data, type = "prob")
library(pROC)
# Compute the ROC curve
roc_obj <- roc(test_data$misinformation, predictions[,2])
# Plot the ROC curve
plot(roc_obj, main = "ROC Curve", print.auc = TRUE)
# Add labels and legend
legend("bottomright", legend = paste("AUC =", round(auc(roc_obj), 2)), cex = 0.8)
# Load the pROC package
library(pROC)
# Compute the ROC curve
roc_obj <- roc(test_data$misinformation, prob_predictions)
# Find the threshold that maximizes Youden's Index
max_index <- which.max(roc_obj$sensitivities + roc_obj$specificities - 1)
threshold <- roc_obj$thresholds[max_index]
# Print the threshold that maximizes Youden's Index
print(paste("Threshold maximizing Youden's Index:", threshold))
# Find the observations in 'tweets' that do not have matching values in 'data$X'
validation <- anti_join(tweets, data, by = "X")
pred = predict(model, validation, type = "prob")
validation$misinformation = pred[,2]
# Apply thresholding to convert probabilities to binary predictions
validation$misinformation <- ifelse(validation$misinformation >= threshold, 1, 0)
# Print the updated 'data' dataframe with the binary predictions
summary(as.factor(validation$misinformation))
summary(as.factor(data$misinformation))
# Fit a random forest model
model <- glm(formula, data = train_data, family = binomial)
# Make predictions on the test data
predictions <- predict(model, newdata = test_data, type = "response")
library(pROC)
# Compute the ROC curve
roc_obj <- roc(test_data$misinformation, predictions)
# Get the directory of the R script
script_dir <- dirname(rstudioapi::getSourceEditorContext()$path)
# Set the working directory
setwd(file.path(script_dir, "../data"))
data = read.csv("classified.csv")
tweets = read.csv("vax_tweets_5.csv")
summary(tweets$X)
# Check for missing numbers in the "X" column
missing_numbers <- setdiff(1:100000, unique(tweets$X))
merged_data <- merge(data, tweets, by = "X")
merged_data$misinformation = as.factor(merged_data$misinformation)
# Assuming you have a merged dataset called merged_data with columns "misinformation" and other variables
# Set a random seed for reproducibility
set.seed(42)
# Split the data into training and testing sets using an 80:20 ratio
train_indices <- sample(nrow(merged_data), 0.8 * nrow(merged_data))
train_data <- merged_data[train_indices, ]
test_data <- merged_data[-train_indices, ]
# Load the randomForest package
library(randomForest)
# Get the column names that start with "hashtag_"
hashtag_columns <- grep("^hashtag_", colnames(tweets), value = TRUE)
# Create the formula for random forest, including the hashtag columns
formula <- as.formula(paste("misinformation ~ polarity_text + subjectivity_text + subjectivity_description + polarity_description + Organizations + Locations + Symptoms + COVID + Vaccination + Politics +
Conspiracy + Slurs + Masks + Miscellaneous + origin +
vaccine_conspiracy + government + pharma + Five_G +
gates + nwo + media +", paste(hashtag_columns, collapse = " + "), collapse = " + "))
formula
# Fit a random forest model
model <- glm(formula, data = train_data, family = binomial)
# Make predictions on the test data
predictions <- predict(model, newdata = test_data, type = "response")
library(pROC)
# Compute the ROC curve
roc_obj <- roc(test_data$misinformation, predictions)
# Plot the ROC curve
plot(roc_obj, main = "ROC Curve", print.auc = TRUE)
# Add labels and legend
legend("bottomright", legend = paste("AUC =", round(auc(roc_obj), 2)), cex = 0.8)
# Load the pROC package
library(pROC)
# Compute the ROC curve
roc_obj <- roc(test_data$misinformation, prob_predictions)
# Find the threshold that maximizes Youden's Index
max_index <- which.max(roc_obj$sensitivities + roc_obj$specificities - 1)
threshold <- roc_obj$thresholds[max_index]
# Print the threshold that maximizes Youden's Index
print(paste("Threshold maximizing Youden's Index:", threshold))
# Find the observations in 'tweets' that do not have matching values in 'data$X'
validation <- anti_join(tweets, data, by = "X")
pred = predict(model, validation, type = "prob")
validation$misinformation = pred[,2]
# Apply thresholding to convert probabilities to binary predictions
validation$misinformation <- ifelse(validation$misinformation >= threshold, 1, 0)
# Print the updated 'data' dataframe with the binary predictions
summary(as.factor(validation$misinformation))
summary(as.factor(data$misinformation))
